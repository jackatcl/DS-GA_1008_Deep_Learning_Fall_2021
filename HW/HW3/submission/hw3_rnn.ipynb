{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hw3_rnn.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"PtcBjMq7YV3f"},"source":["# Homework 3 - Recurrent Neural Networks"]},{"cell_type":"markdown","metadata":{"id":"Rn-cOk1iZTtR"},"source":["In this part of the homework we are going to work with Recurrent Neural Networks, in particular GRU. One of the greatest things that Recurrent Neural Networks can do when working with sequences is retaining data from several timesteps in the past. We are going to explore that property by constructing an 'echo' Recurrent Neural Network.\n","\n","The goal here is to make a model that given a sequence of letters or digits will output that same sequence, but with a certain delay. Let's say the input is a string 'abacaba', we want the model to not output anything for 3 steps (delay length), and then output the original string step by step, except the last 3 characters. So, target output is then 'XXXabac', where 'X' is empty output.\n","\n","This is similar to [this notebook](https://github.com/Atcold/pytorch-Deep-Learning/blob/master/09-echo_data.ipynb) (which you should refer to when doing this assignment), except we're working not with a binary string, but with a sequence of integers between 0 and some N. In our case N is 26, which is the number of letters in the alphabet."]},{"cell_type":"markdown","metadata":{"id":"npLlE973as6x"},"source":["## Dataset\n","\n","Let's implement the dataset. In our case, the data is basically infinite, as we can always generate more examples on the fly, so don't need to load anything from disk."]},{"cell_type":"code","metadata":{"id":"mkEEMyvzIMRx","executionInfo":{"status":"ok","timestamp":1635248924180,"user_tz":240,"elapsed":973,"user":{"displayName":"Long Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08701390897721864097"}}},"source":["import random\n","import string\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from tqdm.notebook import tqdm\n","import torch.optim as optim\n","from torchsummary import summary\n","from matplotlib import pyplot as plt\n","import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n","\n","\n","# Max value of the generated integer. 26 is chosen becuase it's\n","# the number of letters in English alphabet.\n","N = 26\n","\n","\n","def idx_to_onehot(x, k=N+1):\n","  \"\"\" Converts the generated integers to one-hot vectors \"\"\"\n","  ones = torch.sparse.torch.eye(k)\n","  shape = x.shape\n","  res = ones.index_select(0, x.view(-1).type(torch.int64))\n","  return res.view(*shape, res.shape[-1])\n","\n","\n","class EchoDataset(torch.utils.data.IterableDataset):\n","\n","  def __init__(self, delay=4, seq_length=15, size=1000):\n","    self.delay = delay\n","    self.seq_length = seq_length\n","    self.size = size\n","  \n","  def __len__(self):\n","    return self.size\n","\n","  def __getitem__(self, index):\n","    seq = torch.tensor([random.choice(range(1, N + 1)) for i in range(self.seq_length)], dtype=torch.int64)\n","    result = torch.cat((torch.zeros(self.delay), seq[:self.seq_length - self.delay])).type(torch.int64)\n","    return seq, result\n","\n","  def __iter__(self):\n","    \"\"\" Iterable dataset doesn't have to implement __getitem__.\n","        Instead, we only need to implement __iter__ to return\n","        an iterator (or generator).\n","    \"\"\"\n","    for _ in range(self.size):\n","      seq = torch.tensor([random.choice(range(1, N + 1)) for i in range(self.seq_length)], dtype=torch.int64)\n","      result = torch.cat((torch.zeros(self.delay), seq[:self.seq_length - self.delay])).type(torch.int64)\n","      yield seq, result\n","\n","D = 4\n","DATASET_SIZE = 200000\n","ds = EchoDataset(delay=D, size=DATASET_SIZE)"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Hg0_lV4RIR1","executionInfo":{"status":"ok","timestamp":1635248924181,"user_tz":240,"elapsed":17,"user":{"displayName":"Long Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08701390897721864097"}}},"source":[""],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"il8o5K3OItuO","executionInfo":{"status":"ok","timestamp":1635248924181,"user_tz":240,"elapsed":11,"user":{"displayName":"Long Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08701390897721864097"}},"outputId":"d839c081-080b-492d-d8e3-ffc6e8eeaa56"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"nNrZqYURcKSl"},"source":["## Model\n","\n","Now, we want to implement the model. For our purposes, we want to use GRU. The architecture consists of GRU and a decoder. Decoder is responsible for decoding the GRU hidden state to yield a predicting for the next output. The parts you are responsible for filling with your code are marked with `TODO`. "]},{"cell_type":"code","metadata":{"id":"nigN_o4Mb9Nx","executionInfo":{"status":"ok","timestamp":1635248924182,"user_tz":240,"elapsed":9,"user":{"displayName":"Long Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08701390897721864097"}}},"source":["class GRUMemory(torch.nn.Module):\n","\n","  def __init__(self, hidden_size, hidden_layer, output_size):\n","    super().__init__()\n","    #TODO: initialize your submodules\n","    self.output_size = output_size\n","    self.hidden_size = hidden_size\n","    self.hidden_layer = hidden_layer\n","\n","    self.encoder = nn.GRU(\n","        input_size=self.output_size, \n","        hidden_size=self.hidden_size,\n","        num_layers=self.hidden_layer,\n","        batch_first=True, \n","        bias=True)\n","    \n","    self.decoder = nn.Sequential(\n","        nn.Linear(self.hidden_size, self.output_size)\n","    )\n","\n","  def forward(self, x):\n","    # inputs: x - input tensor of shape (batch_size, seq_length, N+1)\n","    # returns:\n","    # logits (scores for softmax) of shape (batch size, seq_length, N + 1)\n","    # TODO implement forward pass\n","    res, hidden = self.encoder(x)\n","    # print(res.shape)\n","    res = self.decoder(res)\n","    # print(res.shape)\n","    # print(1)\n","\n","    return F.log_softmax(res, dim=2), hidden\n","\n","\n","  @torch.no_grad()\n","  def test_run(self, s):\n","    # This function accepts one string s containing lowercase characters a-z. \n","    # You need to map those characters to one-hot encodings, \n","    # then get the result from your network, and then convert the output \n","    # back to a string of the same length, with 0 mapped to ' ', \n","    # and 1-26 mapped to a-z.\n","    self.eval()\n","\n","    x = [ord(i) - ord('a') + 1 for i in s]\n","    x = torch.FloatTensor(x)\n","    x = idx_to_onehot(x).unsqueeze(0).to(device)\n","\n","    # print(x)\n","    # print(x.unsqueeze(0).shape)\n","    res, _ = self(x)\n","    \n","    res = torch.squeeze(res)\n","    res = torch.max(res, 1)\n","    # print(res)\n","    ans = [chr(ord('a') + i - 1) for i in res.indices]\n","    # print(ans)\n","    for idx, (a, b) in enumerate(zip(res.indices, ans)):\n","      if a == 0:\n","        ans[idx] = ' '\n","    \n","    return ''.join(ans)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A9whwmVu9OIx"},"source":["## Training\n","Below you need to implement the training of the model. We give you more freedom as for the implementation. The two limitations are that it has to execute within 10 minutes, and that error rate should be below 1%."]},{"cell_type":"code","metadata":{"id":"lUZkeRnVTNzG","executionInfo":{"status":"ok","timestamp":1635248924182,"user_tz":240,"elapsed":9,"user":{"displayName":"Long Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08701390897721864097"}}},"source":["def test_model(model, sequence_length=15):\n","  \"\"\"\n","  This is the test function that runs 100 different strings through your model,\n","  and checks the error rate.\n","  \"\"\"\n","  total = 0\n","  correct = 0\n","  for i in range(500):\n","    s = ''.join([random.choice(string.ascii_lowercase) for i in range(random.randint(15, 25))])\n","    result = model.test_run(s)\n","    for c1, c2 in zip(s[:-D], result[D:]):\n","      correct += int(c1 == c2)\n","    total += len(s) - D\n","\n","  return correct / total"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"9lV9BscxCCAI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635249191855,"user_tz":240,"elapsed":267681,"user":{"displayName":"Long Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08701390897721864097"}},"outputId":"afa8d1dd-caf6-4b81-a74b-78a751c33ab9"},"source":["import time\n","start_time = time.time()\n","\n","# TODO\n","def get_loss_and_correct(model, batch, criterion, device, hidden):\n","  # Implement forward pass and loss calculation for one batch.\n","  # Remember to move the batch to device.\n","  # \n","  # Return a tuple:\n","  # - loss for the batch (Tensor)\n","  # - number of correctly classified examples in the batch (Tensor)\n","  data, target = batch\n","  target = target.to(device)\n","  # print(data.shape)\n","  data = idx_to_onehot(data).to(device)\n","  # print(data.shape)\n","  output, hidden = model(data)\n","  output = output.permute(0, 2, 1)\n","  loss = criterion(output, target)\n","\n","  accurate_count = 0\n","  # print(accurate_count)\n","\n","  return loss, accurate_count, hidden\n","\n","\n","def step(loss, optimizer):\n","  # Implement backward pass and update.\n","  # TODO\n","  loss.backward()\n","  optimizer.step()\n","\n","\n","N_EPOCHS = 2\n","BATCH_SIZE = 64\n","N = 26\n","HIDDEN_SIZE=64\n","HIDDEN_LAYER_SIZE = 4\n","\n","train_dataloader = torch.utils.data.DataLoader(ds, batch_size=BATCH_SIZE, num_workers=4)\n","\n","model = GRUMemory(HIDDEN_SIZE, HIDDEN_LAYER_SIZE, N+1).to(device)\n","\n","# criterion = nn.CrossEntropyLoss()\n","criterion = torch.nn.NLLLoss()\n","optimizer = torch.optim.Adam(model.parameters(), \n","                             lr=1e-3)\n","\n","model.train()\n","\n","train_losses = []\n","train_accuracies = []\n","validation_losses = []\n","validation_accuracies = []\n","\n","\n","for i in range(N_EPOCHS):\n","  print(i)\n","\n","  model.train()\n","  for data, target in train_dataloader:\n","    data = idx_to_onehot(data).to(device)\n","    target = target.to(device)\n","\n","    optimizer.zero_grad()\n","    out, hidden = model(data)\n","    out = out.permute(0, 2, 1)\n","    loss = criterion(out, target)\n","    loss.backward()\n","\n","    optimizer.step()\n","\n","\n","end_time = time.time()\n","duration = end_time - start_time\n","accuracy = test_model(model)\n","assert duration < 600, 'execution took f{duration:.2f} seconds, which longer than 10 mins'\n","assert accuracy > 0.99, f'accuracy is too low, got {accuracy}, need 0.99'\n","print('tests passed')"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","1\n","tests passed\n"]}]},{"cell_type":"code","metadata":{"id":"U4vJfVN7deXr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635249191856,"user_tz":240,"elapsed":23,"user":{"displayName":"Long Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08701390897721864097"}},"outputId":"4b43a2a9-da1a-453d-86af-6758d434ec38"},"source":["accuracy"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9WhO1BXV8HSk","executionInfo":{"status":"ok","timestamp":1635249191856,"user_tz":240,"elapsed":17,"user":{"displayName":"Long Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08701390897721864097"}},"outputId":"53fd2404-548c-41ca-c4a7-455973179027"},"source":["duration"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["265.5319788455963"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"sB0EVNBtDhpN"},"source":["## Variable delay model\n","\n","Now, to make this more complicated, we want to have varialbe delay. So, now, the goal is to transform a sequence of pairs (character, delay) into a character sequence with given delay. Delay stays constant within one sequence."]},{"cell_type":"markdown","metadata":{"id":"3i_iwX_AEOCH"},"source":["### Dataset\n","As before, we first implement the dataset:"]},{"cell_type":"code","metadata":{"id":"E4G5b8kuEUEd","executionInfo":{"status":"ok","timestamp":1635249191857,"user_tz":240,"elapsed":11,"user":{"displayName":"Long Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08701390897721864097"}}},"source":["class VariableDelayEchoDataset(torch.utils.data.IterableDataset):\n","\n","  def __init__(self, max_delay=8, seq_length=20, size=1000):\n","    self.max_delay = max_delay\n","    self.seq_length = seq_length\n","    self.size = size\n","  \n","  def __len__(self):\n","    return self.size\n","\n","  def __iter__(self):\n","    for _ in range(self.size):\n","      seq = torch.tensor([random.choice(range(1, N + 1)) for i in range(self.seq_length)], dtype=torch.int64)\n","      delay = random.randint(0, self.max_delay)\n","      result = torch.cat((torch.zeros(delay), seq[:self.seq_length - delay])).type(torch.int64)\n","      yield seq, delay, result\n","  \n"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oTRVOND3HEJZ"},"source":["### Model\n","\n","And the model."]},{"cell_type":"code","metadata":{"id":"IYolFIB8Hg0U","executionInfo":{"status":"ok","timestamp":1635249811954,"user_tz":240,"elapsed":254,"user":{"displayName":"Long Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08701390897721864097"}}},"source":["class VariableDelayGRUMemory(torch.nn.Module):\n","\n","  def __init__(self, hidden_size, hidden_layer, output_size, max_delay):\n","    super().__init__()\n","    #TODO\n","    self.output_size = output_size\n","    self.hidden_size = hidden_size\n","    self.hidden_layer = hidden_layer\n","    self.max_delay = max_delay\n","\n","    self.encoder = nn.GRU(\n","        input_size=self.output_size + 1, \n","        hidden_size=self.hidden_size,\n","        num_layers=self.hidden_layer,\n","        batch_first=True, \n","        bias=True)\n","    \n","    self.decoder = nn.Sequential(\n","        nn.Linear(self.hidden_size, self.output_size)\n","    )\n","\n","  def forward(self, x, delays):\n","    # inputs:\n","    # x - tensor of shape (batch size, seq length, N + 1)\n","    # delays - tensor of shape (batch size)\n","    # returns:\n","    # logits (scores for softmax) of shape (batch size, seq_length, N + 1)\n","\n","    # map to 3d representation\n","    delays = delays.view(-1, 1).repeat(1, x.shape[1]).unsqueeze(2)\n","    # print(delays.shape)\n","    inp = torch.cat([x, delays], dim=2)\n","    inp.to(device)\n","\n","    res, hid = self.encoder(inp)\n","    # print(res.shape)\n","\n","    res = self.decoder(res)\n","    # print(res.shape)\n","    \n","    return F.log_softmax(res, dim=2), hidden\n","\n","  @torch.no_grad()\n","  def test_run(self, s, delay):\n","    # This function accepts one string s containing lowercase characters a-z, \n","    # and a delay - the desired output delay.\n","    # You need to map those characters to one-hot encodings, \n","    # then get the result from your network, and then convert the output \n","    # back to a string of the same length, with 0 mapped to ' ', \n","    # and 1-26 mapped to a-z.\n","\n","    # TODO\n","    self.eval()\n","\n","    x = [ord(i) - ord('a') + 1 for i in s]\n","    x = torch.FloatTensor(x)\n","    x = idx_to_onehot(x).unsqueeze(0).to(device)\n","\n","    delays = torch.Tensor([delay]).to(device)\n","    res, _ = self(x, delays)\n","    \n","    res = torch.squeeze(res)\n","    res = torch.max(res, 1)\n","    # print(res)\n","    ans = [chr(ord('a') + i - 1) for i in res.indices]\n","    # print(ans)\n","    for idx, (a, b) in enumerate(zip(res.indices, ans)):\n","      if a == 0:\n","        ans[idx] = ' '\n","    \n","    return ''.join(ans)\n"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"riu3qHWgKjsx"},"source":["### Train\n","\n","As before, you're free to do what you want, as long as training finishes within 10 minutes and accuracy is above 0.99 for delays between 0 and 8."]},{"cell_type":"code","metadata":{"id":"4FZHojnGO3aw","executionInfo":{"status":"ok","timestamp":1635249192052,"user_tz":240,"elapsed":204,"user":{"displayName":"Long Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08701390897721864097"}}},"source":["def test_variable_delay_model(model, seq_length=20):\n","  \"\"\"\n","  This is the test function that runs 100 different strings through your model,\n","  and checks the error rate.\n","  \"\"\"\n","  total = 0\n","  correct = 0\n","  for i in range(500):\n","    s = ''.join([random.choice(string.ascii_lowercase) for i in range(seq_length)])\n","    d = random.randint(0, model.max_delay)\n","    result = model.test_run(s, d)\n","    # print(result, s)\n","    if d > 0:\n","      z = zip(s[:-d], result[d:])\n","    else:\n","      z = zip(s, result)\n","    for c1, c2 in z:\n","      correct += int(c1 == c2)\n","    total += len(s) - d\n","\n","  return correct / total"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"YJ18Ef6vKi4s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635249486218,"user_tz":240,"elapsed":294169,"user":{"displayName":"Long Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08701390897721864097"}},"outputId":"c3802fbe-e1e2-4ce7-ae98-982c40b07ad6"},"source":["import time\n","start_time = time.time()\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device\n","\n","MAX_DELAY = 8\n","SEQ_LENGTH = 20\n","\n","# TODO: implement model training here.\n","N_EPOCHS = 8\n","BATCH_SIZE = 256\n","N = 26\n","HIDDEN_SIZE=64\n","HIDDEN_LAYER_SIZE = 2\n","DATASET_SIZE = 200000\n","\n","ds = VariableDelayEchoDataset(max_delay=MAX_DELAY, seq_length=SEQ_LENGTH, size=DATASET_SIZE)\n","train_dataloader = torch.utils.data.DataLoader(ds, batch_size=BATCH_SIZE, num_workers=4)\n","\n","model = VariableDelayGRUMemory(HIDDEN_SIZE, HIDDEN_LAYER_SIZE, N+1, MAX_DELAY).to(device)\n","\n","# criterion = nn.CrossEntropyLoss()\n","criterion = torch.nn.NLLLoss()\n","optimizer = torch.optim.Adam(model.parameters(), \n","                             lr=1e-3)\n","\n","model.train()\n","\n","for i in range(N_EPOCHS):\n","  print(i)\n","  model.train()\n","  for data, delay, target in train_dataloader:\n","    data = idx_to_onehot(data).to(device)\n","    target = target.to(device)\n","    delay = delay.to(device)\n","    # print(data.shape)\n","\n","    optimizer.zero_grad()\n","    out, hidden = model(data, delay)\n","    out = out.permute(0, 2, 1)\n","    loss = criterion(out, target)\n","    loss.backward()\n","    optimizer.step()\n","\n","end_time = time.time()\n","assert end_time - start_time < 600, 'executing took longer than 10 mins'\n","assert test_variable_delay_model(model) > 0.99, 'accuracy is too low'\n","print('tests passed')"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","tests passed\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qx5CBoywNeNs","executionInfo":{"status":"ok","timestamp":1635249486219,"user_tz":240,"elapsed":16,"user":{"displayName":"Long Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08701390897721864097"}},"outputId":"f7d48aea-eb66-4390-b55e-15a595ef1266"},"source":["end_time - start_time"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["292.61908435821533"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"127mXGltNWZk","executionInfo":{"status":"ok","timestamp":1635249487750,"user_tz":240,"elapsed":1540,"user":{"displayName":"Long Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08701390897721864097"}},"outputId":"030e2246-2c57-4102-df0b-5dfbcd0b12f7"},"source":["test_variable_delay_model(model)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9997483010319658"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pV0xOErfDHZ-","executionInfo":{"status":"ok","timestamp":1635249494811,"user_tz":240,"elapsed":438,"user":{"displayName":"Long Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08701390897721864097"}},"outputId":"3f07f2a1-8d21-453c-a460-2d74503de9b1"},"source":["!nvidia-smi"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Oct 26 11:58:14 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P0    34W / 250W |   1055MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"zVPGYvlWIaAW","executionInfo":{"status":"ok","timestamp":1635249487750,"user_tz":240,"elapsed":9,"user":{"displayName":"Long Chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08701390897721864097"}}},"source":["``"],"execution_count":13,"outputs":[]}]}